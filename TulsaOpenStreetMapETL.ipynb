{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##works cited\n",
    "\n",
    "https://www.debuggex.com/cheatsheet/regex/python\n",
    "\n",
    "https://docs.python.org/2/library/re.html#simulating-scanf\n",
    "\n",
    "https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/\n",
    "\n",
    "https://discussions.udacity.com/t/how-to-set-up-mongodb-locally-windows/185014/2\n",
    "\n",
    "http://stackoverflow.com/questions/18836064/pymongo-method-of-getting-statistics-for-collection-byte-usage\n",
    "\n",
    "http://stackoverflow.com/questions/3366397/delete-everything-in-a-mongodb-database\n",
    "\n",
    "https://codefortulsa.org/2014/01/19/tulsas-first-openstreetmap-editathon/\n",
    "\n",
    "http://stackoverflow.com/questions/12118695/efficient-way-to-remove-keys-with-empty-values-from-a-dict\n",
    "\n",
    "http://stackoverflow.com/questions/11782566/mongodb-select-countdistinct-x-on-an-indexed-column-count-unique-results-for <--what I found when i googled 'count distinct pymongo'\n",
    "\n",
    "https://docs.mongodb.com/getting-started/shell/query/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"ex_HsHtLxQwZ2e4MjSRVh67BkZYBvVRQ.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "street_expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "osm_file = open(OSMFILE, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-level tags:\n",
      "Counter({'nd': 422743, 'tag': 421160, 'node': 339454, 'way': 57047, 'member': 13658, 'relation': 925, 'bounds': 1, 'osm': 1})\n",
      "tags\n",
      "Counter({'tiger': 180014, 'highway': 50071, 'maxspeed': 36564, 'name': 31269, 'addr': 11769, 'lanes': 10689, 'oneway': 10185, 'building': 7038, 'access': 6780, 'service': 5578, 'name_1': 4643, 'gnis': 4036, 'source': 3677, 'amenity': 3221, 'ref': 3050, 'bicycle': 2783, 'placement': 2717, 'power': 2677, 'turn': 2412, 'foot': 2181, 'surface': 1538, 'is_in': 1512, 'landuse': 1349, 'destination': 1234, 'minspeed': 1227, 'bridge': 1165, 'layer': 1112, 'railway': 1005, 'ele': 996, 'leisure': 959, 'crossing': 953, 'type': 930, 'barrier': 923, 'hgv': 897, 'footway': 893, 'NHS': 829, 'operator': 764, 'toll': 756, 'natural': 651, 'religion': 605, 'name_2': 598, 'sport': 595, 'restriction': 587, 'parking': 571, 'waterway': 569, 'shop': 553, 'traffic_calming': 501, 'horse': 419, 'old_name': 413, 'payment': 410, 'place': 391, 'motor_vehicle': 380, 'smoothness': 377, 'construction': 368, 'boundary': 367, 'admin_level': 360, 'maxheight': 356, 'fee': 345, 'postal_code': 333, 'alt_name': 328, 'agricultural': 325, 'moped': 325, 'carriage': 325, 'lit': 324, 'change': 317, 'aeroway': 306, 'segregated': 305, 'opening_hours': 292, 'denomination': 290, 'loc_name': 257, 'maxwidth': 253, 'motorcar': 234, 'maxweight': 232, 'exit_to': 229, 'width': 228, 'frequency': 224, 'goods': 222, 'voltage': 218, 'cycleway': 208, 'cuisine': 196, 'capacity': 189, 'traffic_sign': 185, 'water': 184, 'note': 182, 'route': 173, 'website': 170, 'junction': 169, 'phone': 167, 'tunnel': 165, 'README': 162, 'man_made': 141, 'FIXME': 133, 'usage': 126, 'network': 117, 'cables': 117, 'emergency': 116, 'tourism': 111, 'survey': 98, 'supervised': 96, 'proposed': 90, 'created_by': 84, 'nat_ref': 81, 'basin': 79, 'colour': 77, 'gauge': 72, 'brand': 70, 'park_ride': 66, 'fuel': 61, 'unsigned_ref': 58, 'wikipedia': 56, 'name_3': 56, 'wheelchair': 53, 'internet_access': 48, 'office': 47, 'description': 47, 'generator': 45, 'atm': 45, 'intermittent': 45, 'to': 44, 'from': 44, 'url': 44, 'direction': 42, 'noexit': 41, 'import_uuid': 40, 'smoking': 36, 'tactile_paving': 36, 'area': 34, 'psv': 33, 'wikidata': 33, 'covered': 30, 'state': 28, 'border_type': 28, 'electrified': 27, 'old_railway_operator': 27, 'button_operated': 26, 'disused': 24, 'abandoned': 24, 'source_ref': 21, 'entrance': 21, 'tower': 20, 'recycling': 20, 'distance': 20, 'via': 19, 'terminal': 19, 'noref': 17, 'motorcycle': 16, 'historic': 16, 'old_ref': 15, 'fixme': 15, 'sidewalk': 15, 'population': 15, 'level': 14, 'landcover': 14, 'communication': 14, 'traffic_signals': 14, 'shelter_type': 13, 'lengths': 13, 'noname': 13, 'fireplace': 12, 'embankment': 12, 'golf': 10, 'nist': 10, 'drive_through': 10, 'voltage-high': 9, 'voltage-low': 9, 'reg_name': 9, 'symbol': 9, 'toilets': 9, 'artwork_type': 8, 'bus': 8, 'vehicle': 8, 'dispensing': 8, 'maxstay': 8, 'census': 7, 'male': 7, 'female': 7, 'pk': 7, 'bicycle_parking': 7, 'ford': 7, 'roundtrip': 7, 'location': 6, 'stop': 6, 'cutting': 6, 'history': 6, 'vending': 5, 'email': 5, 'height': 5, 'maxgcweightrating': 5, 'drinking_water': 5, 'attribution': 5, 'modifier': 5, 'fence_type': 5, 'takeaway': 5, 'material': 4, 'designation': 4, 'boat': 4, 'backrest': 4, 'recycling_type': 4, 'fax': 4, 'contact': 4, 'crossing_ref': 4, 'except': 3, 'cycle_network': 3, 'plant': 3, 'craft': 3, 'short_name': 3, 'start_date': 3, 'spirce': 3, 'information': 3, 'shelter': 3, 'delivery': 3, 'ship': 3, 'beds': 3, 'shape': 2, 'seats': 2, 'user_defined_other': 2, 'bin': 2, 'icao': 2, 'bench': 2, 'name_4': 2, 'playground': 2, 'if': 2, 'mtb': 2, 'step_count': 2, 'deep_draft': 2, 'guidepost': 2, 'lcn': 2, 'siren': 2, 'iata': 2, 'healthcare': 2, 'valves': 2, 'wires': 1, 'disabled': 1, 'rooftop': 1, 'drive_in': 1, 'Umbrella': 1, 'tourist_bus': 1, 'faa': 1, 'hour_off': 1, 'HOA_Name': 1, 'hov': 1, 'Shape_STAr': 1, 'lcn_ref': 1, 'pressure': 1, 'stop_id': 1, 'path': 1, 'substation': 1, 'training': 1, 'OBJECTID_1': 1, 'display': 1, 'second_hand': 1, 'military': 1, 'tidal': 1, 'attraction': 1, 'support': 1, 'id': 1, 'authorized': 1, 'was': 1, 'OBJECTID': 1, 'club': 1, 'microbrewery': 1, 'visibility': 1, 'Shape_Leng': 1, 'count': 1, 'roof': 1, 'site': 1, 'Shape_STLe': 1, 'outdoor_seating': 1, 'artist_name': 1, 'highway_1': 1, 'Keyword': 1, 'hour_on': 1, 'surveillance': 1, 'fcc': 1, 'fire_hydrant': 1, 'wifi': 1, 'closest_town': 1, 'sale': 1, 'Mid-Co': 1, 'landmark': 1, 'quantity': 1})\n"
     ]
    }
   ],
   "source": [
    "#first, let's see what tags are present in the data--in case there are any surprises\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "def count_tags(filename):\n",
    "        alltags = []\n",
    "        cnt = Counter()\n",
    "        \n",
    "        for event, elem in ET.iterparse(filename):\n",
    "            alltags.append(elem.tag)\n",
    "            \n",
    "        for tag in alltags:\n",
    "            cnt[tag] += 1\n",
    "                \n",
    "        return cnt\n",
    "\n",
    "print \"top-level tags:\"\n",
    "osm_file = open(OSMFILE, \"r\")\n",
    "print count_tags(osm_file)\n",
    "\n",
    "#from the osm documentation, tags and ways have second-level information\n",
    "def count_second_level_tags(filename, secondlevel):\n",
    "        alltags = []\n",
    "        cnt = Counter()\n",
    "        \n",
    "        for event, elem in ET.iterparse(filename):\n",
    "            if (elem.tag == secondlevel ):\n",
    "                alltags.append(elem.attrib['k'].split(\":\")[0])\n",
    "            \n",
    "        for tag in alltags:\n",
    "            cnt[tag] += 1\n",
    "                \n",
    "        return cnt\n",
    "\n",
    "print \"tags\"\n",
    "osm_file = open(OSMFILE, \"r\")\n",
    "print count_second_level_tags(osm_file,\"tag\")\n",
    "osm_file.close()\n",
    "#finding:  'tiger' is a very common and surprising specialty tag.  'FIXME' is something I'd note on a personal to-do list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 197283, 'lower_colon': 196217, 'other': 27660, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "#let's see if there are any tags with problematic characters, and how many third-level tags exist (tag[tag:tag])\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.match(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.match(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']) is not None:\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map_keys(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map_keys(OSMFILE)\n",
    "pprint.pprint(keys)\n",
    "#finding: we have zero problem characters in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['25or6to4',\n",
      "     'ALeDonne',\n",
      "     'AM909',\n",
      "     'Aaron Lidman',\n",
      "     'Adam Collier',\n",
      "     'Aerdan',\n",
      "     'Andrew Fish',\n",
      "     'AndrewBuck',\n",
      "     'AndrewSnow',\n",
      "     'BCNorwich',\n",
      "     'Baumi',\n",
      "     'Beau Blackford',\n",
      "     'Bryce C Nesbitt',\n",
      "     'Carl Simonson',\n",
      "     'Carlos Moreno',\n",
      "     'Cato_d_Ae',\n",
      "     'CenterElite',\n",
      "     'Cerritus',\n",
      "     'CharleyD',\n",
      "     'Chetan_Gowda',\n",
      "     'Chris Filip',\n",
      "     'Chris Lawrence',\n",
      "     'ChrisZontine',\n",
      "     'ChrissW-R1',\n",
      "     'CloCkWeRX',\n",
      "     'Computer Repair of Tulsa',\n",
      "     'Constable',\n",
      "     'DK869',\n",
      "     'DKNOTT',\n",
      "     'DLichti',\n",
      "     'Dan White',\n",
      "     'DanHomerick',\n",
      "     'DanPendergast',\n",
      "     'Daniel Jeffries',\n",
      "     'DaveHansenTiger',\n",
      "     'DennisL',\n",
      "     'DietCoke99',\n",
      "     'ELadner',\n",
      "     'Easky30',\n",
      "     'ElWebDev',\n",
      "     'Eljot8472',\n",
      "     'Eric Godwin',\n",
      "     'ErikSASSI',\n",
      "     'EuleKC',\n",
      "     'FIM',\n",
      "     'FTA',\n",
      "     'Fa7C0N',\n",
      "     'FvGordon',\n",
      "     'Geogast',\n",
      "     'GerdP',\n",
      "     'GoWestTravel',\n",
      "     'GreggCarlson',\n",
      "     'Groovecoder',\n",
      "     'Guts Admin',\n",
      "     'Gutsycat',\n",
      "     'HaileyMilsten',\n",
      "     'Hartmut Holzgraefe',\n",
      "     'Hawken Rives',\n",
      "     'HolgerJeromin',\n",
      "     'Humus015',\n",
      "     'Hundehalter',\n",
      "     'Iowa Kid',\n",
      "     'J Dungan',\n",
      "     'JDOklahoma',\n",
      "     'JasonWoof',\n",
      "     'Jedrzej Pelka',\n",
      "     'Jesse Leslie',\n",
      "     'Joe Hart',\n",
      "     'John Gregorovic',\n",
      "     'JohnDeery',\n",
      "     'Johnny Mapperseed',\n",
      "     'Jonas311',\n",
      "     'JubalSackett',\n",
      "     'Judass',\n",
      "     'Jzooor',\n",
      "     'K Naik',\n",
      "     'Kbreit',\n",
      "     'Keith Lewis',\n",
      "     'KristenK',\n",
      "     'LogicalViolinist',\n",
      "     'Luis36995',\n",
      "     'Luiyo',\n",
      "     'MKnight',\n",
      "     'MStenberg',\n",
      "     'Maarten Deen',\n",
      "     'Manu1400',\n",
      "     'Maskulinum',\n",
      "     'Med',\n",
      "     'Michael Hall',\n",
      "     'Michael Whitlatch',\n",
      "     \"Mike O'Connor\",\n",
      "     'MikeN',\n",
      "     'Minh Nguyen',\n",
      "     'Minigeek',\n",
      "     'MrForbes',\n",
      "     'Munchabunch',\n",
      "     'Musab94',\n",
      "     'MyersMM',\n",
      "     'NAIPetrous',\n",
      "     'NE2',\n",
      "     'NE3',\n",
      "     'NayanataraM',\n",
      "     'Nebain',\n",
      "     'Negnet Solutions',\n",
      "     'Ngineer',\n",
      "     'Noframe',\n",
      "     'Nolan Crees',\n",
      "     'Nzara',\n",
      "     'OSMF Redaction Account',\n",
      "     'Olyon',\n",
      "     'Omnific',\n",
      "     'Patrick Forringer',\n",
      "     'Paul Johnson',\n",
      "     'Peter14',\n",
      "     'Phil Scherer',\n",
      "     'PlaneMad',\n",
      "     'Pnrrth',\n",
      "     'Polarbear',\n",
      "     'Polarbear-repair',\n",
      "     'PrometheusAvV',\n",
      "     'Quizzys',\n",
      "     'R0bst3r',\n",
      "     'ReinerMeyer',\n",
      "     'RetiredInNH',\n",
      "     'RichRico',\n",
      "     'RichRico_labuildings',\n",
      "     'Richard',\n",
      "     'RichardCorbin',\n",
      "     'RoadGeek_MD99',\n",
      "     'Roadrunner21',\n",
      "     'Rovastar',\n",
      "     'Rub21',\n",
      "     'SD Mapman',\n",
      "     'Sanderd17',\n",
      "     'SathyaPendyala',\n",
      "     'Scott Smith',\n",
      "     'Shmias',\n",
      "     'SomeoneElse_Revert',\n",
      "     'Spanholz',\n",
      "     'Sparks',\n",
      "     'SquirrelZero',\n",
      "     'SteRos',\n",
      "     'StellanL',\n",
      "     'Stephie115',\n",
      "     'Steven Vance',\n",
      "     'Sundance',\n",
      "     'Syl',\n",
      "     'TIGERcnl',\n",
      "     'T_9er',\n",
      "     'Ted McFarland',\n",
      "     'TheDude05',\n",
      "     'Thomas8122',\n",
      "     'Timco',\n",
      "     'Timothy Smith',\n",
      "     'ToeBee',\n",
      "     'ToffeHoff',\n",
      "     'Tom Tulsa',\n",
      "     'TomHynes',\n",
      "     'Tom_Holland',\n",
      "     'TonyMa',\n",
      "     'TorhamZed',\n",
      "     'Tulsa Fin Tube',\n",
      "     'Turtlewings',\n",
      "     'Vlad',\n",
      "     'Warhobbit',\n",
      "     'Welshie',\n",
      "     'WernerP',\n",
      "     'Wolfram Sobotta',\n",
      "     'Yongduk',\n",
      "     'ZStover',\n",
      "     'Zartbitter',\n",
      "     'ZiggyTheHamster',\n",
      "     'aarthy',\n",
      "     'abel801',\n",
      "     'adamos',\n",
      "     'adjuva',\n",
      "     'alexrudd',\n",
      "     'amillar',\n",
      "     'andrewpmk',\n",
      "     'andsmi',\n",
      "     'andy51edge',\n",
      "     'andygol',\n",
      "     'bahnpirat',\n",
      "     'balrog-kun',\n",
      "     'bbmiller',\n",
      "     'bdiscoe',\n",
      "     'blazeafar',\n",
      "     'bondah',\n",
      "     'bot-mode',\n",
      "     'brnrkm',\n",
      "     'bugo348',\n",
      "     'bwarren',\n",
      "     'calfarome',\n",
      "     'cdavila',\n",
      "     'cgu66',\n",
      "     'chasu',\n",
      "     'clarkrugby',\n",
      "     'claysmalley',\n",
      "     'codybrom',\n",
      "     'colindt',\n",
      "     'compdude',\n",
      "     'crazy_kea',\n",
      "     'dannykath',\n",
      "     'davidearl',\n",
      "     'derFred',\n",
      "     'dhigbee',\n",
      "     'dmw918',\n",
      "     'dr ingrid',\n",
      "     'drugdoc99',\n",
      "     'dufekin',\n",
      "     'duplico',\n",
      "     'earthsmartcon',\n",
      "     'ediyes',\n",
      "     'elbatrop',\n",
      "     'emacsen',\n",
      "     'eric22',\n",
      "     'erjiang',\n",
      "     'esenge1',\n",
      "     'espidan',\n",
      "     'expressautomotiveandtire',\n",
      "     'fbax',\n",
      "     'fenster_24',\n",
      "     'floscher',\n",
      "     'frankh24',\n",
      "     'fredjunod',\n",
      "     'futureshoes',\n",
      "     'gcjunge',\n",
      "     'geochrome',\n",
      "     'ghorne',\n",
      "     'gkerns',\n",
      "     'gormo',\n",
      "     'greggerm',\n",
      "     'h2g2bob',\n",
      "     'h4ck3rm1k3',\n",
      "     'happy5214',\n",
      "     'har777',\n",
      "     'hfyu',\n",
      "     'highbuilder',\n",
      "     'hmpfgnrrr',\n",
      "     'hno2',\n",
      "     'hobbesvsboyle',\n",
      "     'hofoen',\n",
      "     'hoperestorative',\n",
      "     'hopfavogl',\n",
      "     'hustonweir487',\n",
      "     'hybridOL',\n",
      "     'iandees',\n",
      "     'if6iiyjr',\n",
      "     'jacobbraeutigam',\n",
      "     'jamesavery',\n",
      "     'jazztunes',\n",
      "     'jdavidbakr',\n",
      "     'jeff9228',\n",
      "     'jharpster',\n",
      "     'jinalfoflia',\n",
      "     'jnbtcr',\n",
      "     'jonesydesign',\n",
      "     'jotzt',\n",
      "     'jpmartin1977',\n",
      "     'jsatt',\n",
      "     'jumbanho',\n",
      "     'jwagenet',\n",
      "     'jwhitlock',\n",
      "     'karitotp',\n",
      "     'katadunn',\n",
      "     'kisaa',\n",
      "     'klusark',\n",
      "     'kopiersperre',\n",
      "     'kre3d',\n",
      "     'lsmith099',\n",
      "     'lxbarth',\n",
      "     'maggot27',\n",
      "     'maigel',\n",
      "     'malcolmh',\n",
      "     'malenki',\n",
      "     'manings',\n",
      "     'marty74301',\n",
      "     'matthieun',\n",
      "     'maxerickson',\n",
      "     'mcm55',\n",
      "     'mdk',\n",
      "     'mhenson',\n",
      "     'michael colvin',\n",
      "     'michalg0x5a',\n",
      "     'mihaii_telenav',\n",
      "     'mono11',\n",
      "     'mrmakeit',\n",
      "     'msdess',\n",
      "     'mueschel',\n",
      "     'mvexel',\n",
      "     'mwinslett',\n",
      "     'nabelly',\n",
      "     'neuhausr',\n",
      "     'nickb',\n",
      "     'nikhilprabhakar',\n",
      "     'nithinkamath',\n",
      "     'nm7s9',\n",
      "     'nycnikato',\n",
      "     'nyuriks',\n",
      "     'oba510',\n",
      "     'okilimu',\n",
      "     'oldtopos',\n",
      "     'owenh',\n",
      "     'pankdm',\n",
      "     'paulmach',\n",
      "     'pete404',\n",
      "     'phillipsandjohnson',\n",
      "     'piligab',\n",
      "     'polyorchid',\n",
      "     'poornibadrinath',\n",
      "     'pratikyadav',\n",
      "     'pschonmann',\n",
      "     'pverbrug',\n",
      "     'pyram',\n",
      "     'radison',\n",
      "     'raisedabove05',\n",
      "     'ramyaragupathy',\n",
      "     'reBOOT918',\n",
      "     'reunify_aarti',\n",
      "     'richard worl',\n",
      "     'rickmastfan67',\n",
      "     'ridixcr',\n",
      "     'rkachelriess',\n",
      "     'rolandg',\n",
      "     'rollercow',\n",
      "     'rumpelsocke',\n",
      "     'ruph',\n",
      "     'ruthmaben',\n",
      "     'rza31',\n",
      "     'salix01',\n",
      "     'samely',\n",
      "     'samuelestabrook',\n",
      "     'sanchi',\n",
      "     'sejohnson',\n",
      "     'sephillips',\n",
      "     'shravan91',\n",
      "     'skquinn',\n",
      "     'skucera',\n",
      "     'smsm1',\n",
      "     'sneezye',\n",
      "     'spanglercr',\n",
      "     'srividya_c',\n",
      "     'stevea',\n",
      "     'stucki1',\n",
      "     'supernailsok',\n",
      "     'swimdb',\n",
      "     'tdjones74021',\n",
      "     'techlady',\n",
      "     'territorytools',\n",
      "     'texasmapper',\n",
      "     'thegadgetcompok',\n",
      "     'thejstone2002',\n",
      "     'thetravelg',\n",
      "     'tippfeler',\n",
      "     'tunnelbauer',\n",
      "     'tvsrkp',\n",
      "     'ubahnverleih',\n",
      "     'uboot',\n",
      "     'ulfl',\n",
      "     'upendrakarukonda',\n",
      "     'user_5359',\n",
      "     'voschix',\n",
      "     'wambacher',\n",
      "     'werner2101',\n",
      "     'whiteknightok',\n",
      "     'wierdo',\n",
      "     'wmann',\n",
      "     'wolfgang8741',\n",
      "     'woodpeck_fixbot',\n",
      "     'woodpeck_repair',\n",
      "     'worldwidewolford',\n",
      "     'wp6890',\n",
      "     'xybot',\n",
      "     'yurasi',\n",
      "     'zehpunktbarron',\n",
      "     'zephyr',\n",
      "     'zer0number',\n",
      "     'zeromap'])\n"
     ]
    }
   ],
   "source": [
    "#TODO: Consider changing code to count # of times user has contributed--code from count_tags would work\n",
    "#Let's see who's contributing to the Tulsa map\n",
    "def get_user(element):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    user = element.get('user')\n",
    "    return user\n",
    "\n",
    "\n",
    "def process_map_users(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for child in element:\n",
    "            user = get_user(child)\n",
    "            if user is not None:\n",
    "                users.add(user)\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "users = process_map_users(OSMFILE)\n",
    "pprint.pprint(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1045': {'1045'},\n",
       "             '126': {'South Harvard Avenue #126'},\n",
       "             '129': {'129'},\n",
       "             '167': {'Oklahoma State Highway 167'},\n",
       "             '2502': {'2502'},\n",
       "             '503': {'503'},\n",
       "             '66': {'North Old Highway 66'},\n",
       "             '97': {'State Highway 97'},\n",
       "             'A': {'E 71 St #A', 'South Peoria Place, Apt A'},\n",
       "             'Archer': {'Archer'},\n",
       "             'Ave': {'N Lewis Ave',\n",
       "              'S Harvard Ave',\n",
       "              'S Peoria Ave',\n",
       "              'South A Ave'},\n",
       "             'Ave.': {'N. Trenton Ave.'},\n",
       "             'Bouleavard': {'North Martin Luther King, Junior Bouleavard'},\n",
       "             'Breckenridge': {'E Breckenridge'},\n",
       "             'Brook': {'Pebble Brook'},\n",
       "             'Center': {'Civic Center', 'Williams Center'},\n",
       "             'Cherokee': {'S Cherokee', 'South Cherokee'},\n",
       "             'Circle': {'Boise Circle',\n",
       "              'Fox Run Circle',\n",
       "              'North Hemlock Circle',\n",
       "              'South Joshua Circle'},\n",
       "             'Dr': {'S Memorial Dr'},\n",
       "             'Dr.': {'South Memorial Dr.'},\n",
       "             'East': {'South 101st Avenue East',\n",
       "              'South 107th Avenue East',\n",
       "              'South 87th Avenue East',\n",
       "              'South Sheridan Road East',\n",
       "              'South Toledo Avenue East'},\n",
       "             'Expressway': {'Broken Arrow Expressway',\n",
       "              'North Owasso Expressway',\n",
       "              'Owasso Expressway'},\n",
       "             'Florence': {'West Florence'},\n",
       "             'King': {'King'},\n",
       "             'Memorial': {'South Memorial'},\n",
       "             'N': {'E 36th st N'},\n",
       "             'North': {'East 116th Street North',\n",
       "              'East 146th Street North',\n",
       "              'East 30th Street North',\n",
       "              'East 47th Street North',\n",
       "              'East 56th Street North',\n",
       "              'East 80th Street North',\n",
       "              'East 88th Place North',\n",
       "              'East 95th Court North',\n",
       "              'East 96th Street North',\n",
       "              'East 97th Place North',\n",
       "              'East Pine Street North',\n",
       "              'West 28th Street North',\n",
       "              'West 36th Street North'},\n",
       "             'Promenade': {'Tulsa Promenade'},\n",
       "             'Rd': {'E BA Frontage Rd', 'N Lynn Lane Rd', 'S. Sheridan Rd'},\n",
       "             'Sheridan': {'Sheridan'},\n",
       "             'South': {'East 106th Street South',\n",
       "              'East 112th Place South',\n",
       "              'East 133rd Place South',\n",
       "              'East 136th Street South',\n",
       "              'East 138th Place South',\n",
       "              'East 138th Street South',\n",
       "              'East 139th Street South',\n",
       "              'East 140th Street South',\n",
       "              'East 151st Street South',\n",
       "              'East 21st Street South',\n",
       "              'East 38th Place South',\n",
       "              'East 48th Street South',\n",
       "              'East 60th Street South',\n",
       "              'East 61st Street South',\n",
       "              'East 71st Street South',\n",
       "              'East 87th Street South',\n",
       "              'East 91st Street South',\n",
       "              'West 112th Street South',\n",
       "              'West 120th Place South',\n",
       "              'West 124th Street South',\n",
       "              'West 21st Street South'},\n",
       "             'St': {'S Quincy St'},\n",
       "             'T': {'S Mingo Rd #T'},\n",
       "             'West': {'South 49th Avenue West'},\n",
       "             'independance': {'independance'},\n",
       "             'sheridan': {'sheridan'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Personally, I abbreviate street names like Court to Ct, so I expect some of that in the Tulsa data set.\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "audit(OSMFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#there's some ugly data above, it warrants a cleanup.  Creating a little function to tidy street names.\n",
    "\n",
    "mapping = { \"Ave.\": \"Avenue\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Bouleavard\" : \"Boulevard\",\n",
    "            \"Dr.\" : \"Drive\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "\n",
    "            }\n",
    "\n",
    "def update_street_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected and street_type in mapping:\n",
    "            return name.replace(street_type,mapping[street_type])\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beginwplus': 63,\n",
      " 'numeric': 2,\n",
      " 'numericdashes': 66,\n",
      " 'other': 7,\n",
      " 'problemchars': 31}\n"
     ]
    }
   ],
   "source": [
    "#Oklahoma was pretty slow on using NNN-NNN-NNNN phone numbers.  \n",
    "#My hometown didn't use NNN-NNNN until we were forced to in the late 90's.\n",
    "\n",
    "numeric = re.compile(r'^([0-9])*$')\n",
    "numericdashes = re.compile(r'^([0-9]|\\-)*$')\n",
    "\n",
    "def phone_number_format(element, keys):\n",
    "    other_formatted_numbers = []\n",
    "    problem_formatted_numbers = []\n",
    "    \n",
    "    if element.tag == \"tag\" and element.attrib['k'] == \"phone\":\n",
    "        if numeric.match(element.attrib['v']):\n",
    "            keys['numeric'] += 1\n",
    "        if numericdashes.match(element.attrib['v']):\n",
    "            keys['numericdashes'] += 1\n",
    "        elif element.attrib['v'][0] == '+' and numericdashes.match(element.attrib['v'][1:]):\n",
    "            keys['beginwplus'] += 1\n",
    "        elif problemchars.search(element.attrib['v']) is not None:\n",
    "            keys['problemchars'] += 1\n",
    "            problem_formatted_numbers.append(element.attrib['v'])\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "            other_formatted_numbers.append(element.attrib['v'])\n",
    "    \n",
    "#     if len(other_formatted_numbers) > 0:\n",
    "#         print other_formatted_numbers\n",
    "    \n",
    "#     if len(problem_formatted_numbers) > 0:\n",
    "#         print problem_formatted_numbers\n",
    "    \n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map_phonekeys(filename):\n",
    "    keys = {\"numeric\": 0, \"numericdashes\": 0, \"beginwplus\":0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = phone_number_format(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "phonekeys = process_map_phonekeys(OSMFILE)\n",
    "pprint.pprint(phonekeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#there's some variation in the phone number formatting.  Let's use a phone number library to tidy these.\n",
    "import phonenumbers as pn\n",
    "\n",
    "def tidy_phone(phonenumber):\n",
    "    return pn.format_number(pn.parse(phonenumber, 'US'), pn.PhoneNumberFormat.NATIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first, declare the data layout we'd like:\n",
    "\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "FIELDS = {\n",
    "            \"id\": \"id\",\n",
    "            \"type\": \"childtype\",\n",
    "            \"visible\":\"visible\",\n",
    "            \"created\": {\n",
    "                      \"version\":\"version\",\n",
    "                      \"changeset\":\"changeset\",\n",
    "                      \"timestamp\":\"timestamp\",\n",
    "                      \"user\":\"user\",\n",
    "                      \"uid\":\"uid\"\n",
    "                    },\n",
    "            \"pos\": [\"lat\", \"lon\"],\n",
    "            \"address\": {\n",
    "                      \"housenumber\": \"housenumber\",\n",
    "                      \"postcode\": \"postcode\",\n",
    "                      \"street\": \"street\"\n",
    "                    },\n",
    "            \"amenity\": \"amenity\",\n",
    "            \"cuisine\": \"cuisine\",\n",
    "            \"name\": \"name\",\n",
    "            \"phone\": \"phone\",\n",
    "            \"user\" : \"user\",\n",
    "            \"node_refs\" : \"node_refs\",\n",
    "            \"othertags\" : \"othertags\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a function to tidy the values by removing blank sets\n",
    "def tidy_values(node):\n",
    "    node = {k: v for k, v in node.items() if v!={} and v!=[]}\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a function to remove \n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        for key, value in FIELDS.iteritems():\n",
    "            try:\n",
    "                node[value] = element.attrib[key]\n",
    "                try:\n",
    "                    node['phone'] = tidy_phone(node['phone'])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            except KeyError:\n",
    "                if key == \"type\":\n",
    "                    node['type'] = element.tag\n",
    "                elif key == \"created\":\n",
    "                    node['created'] = dict()\n",
    "                    for ckey, cvalue in FIELDS[key].iteritems():\n",
    "                        node['created'][cvalue] = element.attrib[ckey]\n",
    "                elif key == \"pos\":\n",
    "                    try:\n",
    "                        node[key] = [float(element.attrib['lat']), float(element.attrib['lon'])]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                elif key == \"address\":\n",
    "                    node['address'] = dict()\n",
    "                    for akey, avalue in FIELDS[key].iteritems():\n",
    "                        try:\n",
    "                            node['address'][avalue] = update_street_name(element.attrib[akey])\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                elif key == \"node_refs\":\n",
    "                    try:\n",
    "                        node['node_refs']\n",
    "                    except:\n",
    "                        node['node_refs'] = []\n",
    "                    for nd in element.findall('nd'):\n",
    "                        node['node_refs'].append(nd.attrib['ref'])\n",
    "                else:\n",
    "                    for tag in element.iter(\"tag\"):\n",
    "                        if tag.attrib['k'] == key:\n",
    "                            node[key] = tag.attrib['v']\n",
    "                        elif tag.attrib['k'][:5] == 'addr:' and tag.attrib['k'].count(\":\") == 1:\n",
    "                            if 'address' not in node:\n",
    "                                node['address'] = dict()\n",
    "                            addressdetails = tag.attrib['k'].split(':')\n",
    "                            node['address'][addressdetails[1]] = tag.attrib['v']\n",
    "                        elif tag.attrib['k'] == 'phone':\n",
    "                            node['phone'] = tidy_phone(tag.attrib['v'])\n",
    "                        elif \":\" not in tag.attrib['k'] and problemchars.search(tag.attrib['k']) is None:\n",
    "                            node[tag.attrib['k']] = tag.attrib['v']\n",
    "                        elif ':' in tag.attrib['k'] and problemchars.search(tag.attrib['k']) is None:\n",
    "                            details = tag.attrib['k'].split(':')\n",
    "                            try:\n",
    "                                if details[0] not in node:\n",
    "                                    node[details[0]] = dict()\n",
    "                                node[details[0]][details[1]] = tag.attrib['v']\n",
    "                            except TypeError:\n",
    "                                node[details[0]] = {details[1] : tag.attrib['v']}\n",
    "        node = tidy_values(node)\n",
    "        return node\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "# call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "# additional spaces to the output, making it significantly larger.\n",
    "data = process_map(OSMFILE, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barrier': 'gate',\n",
      " 'created': {'changeset': '7252326',\n",
      "             'timestamp': '2011-02-11T06:46:06Z',\n",
      "             'uid': '92286',\n",
      "             'user': 'Paul Johnson',\n",
      "             'version': '2'},\n",
      " 'id': '102756508',\n",
      " 'pos': [36.021577, -95.9037904],\n",
      " 'type': 'node',\n",
      " 'user': 'Paul Johnson'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##New file made, time to pull it into MongoDB\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "db = get_db('TulsaOSM')\n",
    "\n",
    "##run in command line:\n",
    "##C:\\Program Files\\MongoDB\\Server\\3.4\\bin>mongoimport /d TulsaOSM /c OSM /file:\"C:\\Users\\agdje\\OneDrive\\Documents\\Udacity\\Nanodegree\\DataAnalysis\\P3WrangleOpenStreetMap\\ex_HsHtLxQwZ2e4MjSRVh67BkZYBvVRQ.osm.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'storageSize': 12107776.0, u'ok': 1.0, u'avgObjSize': 278.54168841944914, u'views': 0, u'db': u'TulsaOSM', u'indexes': 1, u'objects': 396501, u'collections': 1, u'numExtents': 0, u'dataSize': 110442058.0, u'indexSize': 1396736.0}\n"
     ]
    }
   ],
   "source": [
    "#now that it's imported, what's the size\n",
    "print db.command('dbstats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_pipeline():\n",
    "    pipeline = [\n",
    "        { \"$match\" : { \"user\" : { \"$exists\" : True }}}, ##only count changes with a username attached\n",
    "        { \"$group\" : { \"_id\" : \"$user\", \"count\": { \"$sum\" : 1 }}},\n",
    "        { \"$sort\" : { \"count\" : -1 }},\n",
    "        { \"$limit\" : 1 }\n",
    "    ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.OSM.aggregate(pipeline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'barrier': u'gate', u'created': {u'changeset': u'7252326', u'user': u'Paul Johnson', u'version': u'2', u'uid': u'92286', u'timestamp': u'2011-02-11T06:46:06Z'}, u'pos': [36.021577, -95.9037904], u'user': u'Paul Johnson', u'_id': ObjectId('58699e8267971b4d0dac7e0d'), u'type': u'node', u'id': u'102756508'}\n"
     ]
    }
   ],
   "source": [
    "print db.OSM.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'Paul Johnson', u'count': 133819}\n"
     ]
    }
   ],
   "source": [
    "pipeline = user_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "pprint.pprint(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##FINDING \n",
    "Paul Johnson, the user with the highest number of changes, sounded familiar so I looked -- in 2014 he had over a million nodes in total changes\n",
    "https://codefortulsa.org/2014/01/19/tulsas-first-openstreetmap-editathon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#how many total users have contributed? COUNT DISTINCT equivalent\n",
    "def count_users_pipeline():\n",
    "    pipeline = [\n",
    "        { \"$match\" : { \"user\" : { \"$exists\" : True }}}, ##only count changes with a username attached\n",
    "        { \"$group\" : { \"_id\" : \"$user\", \"count\": { \"$sum\" : 1 }}},\n",
    "        { \"$group\" : { \"_id\" : \"unique users\", \"count\" : { \"$sum\" : 1 }}}\n",
    "    ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'unique users', u'count': 371}\n"
     ]
    }
   ],
   "source": [
    "pipeline = count_users_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "pprint.pprint(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339454"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of nodes\n",
    "db.OSM.find( { \"type\" : \"node\" }).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57047"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of ways\n",
    "db.OSM.find( { \"type\" : \"way\" }).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#There's a running local joke about whether there are more churches or bars in Tulsa.\n",
    "def count_amenities_pipeline():\n",
    "    pipeline = [\n",
    "        { \"$match\" : {\"amenity\" : { \"$exists\" : True }, \"type\" : \"node\" }}, #only nodes with an amenity tag\n",
    "        { \"$group\" : { \"_id\" : \"$amenity\", \"count\": {\"$sum\" : 1 }}},\n",
    "        { \"$sort\" : { \"count\" : -1 }}\n",
    "    ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'place_of_worship', u'count': 554},\n",
      " {u'_id': u'school', u'count': 140},\n",
      " {u'_id': u'fast_food', u'count': 92},\n",
      " {u'_id': u'restaurant', u'count': 76},\n",
      " {u'_id': u'fountain', u'count': 67}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = count_amenities_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "# pprint.pprint(result)\n",
    "pprint.pprint(result[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bars aren't even in the top five in this data set.  I'm selecting out places likely to be attended solely for drinking vs churches.\n",
    "def count_certain_amenities_pipeline():\n",
    "    pipeline = [\n",
    "        { \"$match\" : {\"amenity\" : { \"$in\" : [\"place_of_worship\", \"bar\", \"pub\", \"liquor\", \"nightclub\"]} , \"type\" : \"node\" }}, #only the nodes we're interested in\n",
    "        { \"$group\" : { \"_id\" : \"$amenity\", \"count\": {\"$sum\" : 1 }}},\n",
    "        { \"$sort\" : { \"count\" : -1 }}\n",
    "    ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'place_of_worship', u'count': 554},\n",
      " {u'_id': u'bar', u'count': 9},\n",
      " {u'_id': u'pub', u'count': 8},\n",
      " {u'_id': u'liquor', u'count': 2},\n",
      " {u'_id': u'nightclub', u'count': 1}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = count_certain_amenities_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
